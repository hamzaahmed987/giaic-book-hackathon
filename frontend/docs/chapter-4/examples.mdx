---
sidebar_position: 3
title: "Practical Examples"
description: Building a complete RAG system
---

# Practical Examples

## Example 1: Complete RAG Pipeline

```python
# rag_pipeline.py
from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance
import uuid

class RAGPipeline:
    def __init__(self, qdrant_url: str, qdrant_api_key: str):
        self.openai = OpenAI()
        self.qdrant = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)
        self.collection = "documents"

    def get_embedding(self, text: str) -> list[float]:
        response = self.openai.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding

    def chunk_document(self, text: str, chunk_size: int = 500) -> list[str]:
        words = text.split()
        chunks = []
        for i in range(0, len(words), chunk_size):
            chunk = " ".join(words[i:i + chunk_size])
            chunks.append(chunk)
        return chunks

    def index_document(self, document: str, metadata: dict = None):
        chunks = self.chunk_document(document)

        points = []
        for i, chunk in enumerate(chunks):
            embedding = self.get_embedding(chunk)
            points.append(PointStruct(
                id=str(uuid.uuid4()),
                vector=embedding,
                payload={
                    "text": chunk,
                    "chunk_index": i,
                    **(metadata or {})
                }
            ))

        self.qdrant.upsert(collection_name=self.collection, points=points)

    def query(self, question: str, top_k: int = 5) -> str:
        # Retrieve
        query_embedding = self.get_embedding(question)
        results = self.qdrant.search(
            collection_name=self.collection,
            query_vector=query_embedding,
            limit=top_k
        )

        context = "\n\n".join([r.payload["text"] for r in results])

        # Generate
        response = self.openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": f"""Answer based on the following context.
If the answer isn't in the context, say "I don't have information about that."

Context:
{context}"""},
                {"role": "user", "content": question}
            ]
        )

        return response.choices[0].message.content


# Usage
rag = RAGPipeline(qdrant_url="...", qdrant_api_key="...")
rag.index_document("Your document content here...", {"source": "chapter1"})
answer = rag.query("What is explained in this document?")
```

## Example 2: RAG with Citations

```python
def query_with_citations(self, question: str) -> dict:
    query_embedding = self.get_embedding(question)
    results = self.qdrant.search(
        collection_name=self.collection,
        query_vector=query_embedding,
        limit=5
    )

    # Build context with source tracking
    sources = []
    context_parts = []
    for i, r in enumerate(results):
        context_parts.append(f"[{i+1}] {r.payload['text']}")
        sources.append({
            "id": i + 1,
            "source": r.payload.get("source", "Unknown"),
            "score": r.score
        })

    context = "\n\n".join(context_parts)

    response = self.openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": f"""Answer using the numbered sources.
Cite sources using [1], [2], etc.

Sources:
{context}"""},
            {"role": "user", "content": question}
        ]
    )

    return {
        "answer": response.choices[0].message.content,
        "sources": sources
    }
```

---

Continue to [Exercises](/book/chapter-4/exercises).
